{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import GooglePalm\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for file in os.listdir(\"docs\"):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = \"./docs/\" + file\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif file.endswith('.docx') or file.endswith('.doc'):\n",
    "        doc_path = \"./docs/\" + file\n",
    "        loader = Docx2txtLoader(doc_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif file.endswith('.txt'):\n",
    "        text_path = \"./docs/\" + file\n",
    "        loader = TextLoader(text_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents, embedding=GooglePalmEmbeddings(google_api_key=api_key), persist_directory=\"./data\")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_qa = ConversationalRetrievalChain.from_llm(\n",
    "    GooglePalm(google_api_key=api_key),\n",
    "    vectordb.as_retriever(search_kwargs={'k': 6}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = \"\\033[0;33m\"\n",
    "green = \"\\033[0;32m\"\n",
    "white = \"\\033[0;39m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;33m---------------------------------------------------------------------------------\n",
      "Welcome to the DocBot. You are now ready to start interacting with your documents\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "print(f\"{yellow}---------------------------------------------------------------------------------\")\n",
    "print('Welcome to the DocBot. You are now ready to start interacting with your documents')\n",
    "print('---------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39mAnswer: ['Xuezhi Wang', 'Jason Wei', 'Dale Schuurmans', 'Quoc Le', 'Ed Chi', 'Sharan Narang', 'Aakanksha Chowdh-\n",
      "ery', and 'Denny Zhou']\n",
      "\u001b[0;39mAnswer: Optimization trajectory is a list of past solutions with their corresponding optimization scores.\n",
      "\u001b[0;39mAnswer: The meta-prompt contains the following two essential parts:\n",
      "1. Optimization problem description.\n",
      "2. Optimization trajectory.\n",
      "\u001b[0;39mAnswer: The meta-prompt contains two essential parts.\n",
      "1. Optimization problem description.\n",
      "2. Optimization trajectory.\n",
      "\u001b[0;39mAnswer: This paper proposes Optimization by PROmpting (OPRO), a simple and effective approach to utilize large language models (LLMs) as optimizers. OPRO enables quick adaptation to different tasks by changing the problem description in the prompt, and the optimization process can be customized by adding instructions to specify the desired properties of the solutions.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query = input(f\"{green}Prompt: \")\n",
    "    if query == \"exit\" or query == \"quit\" or query == \"q\" or query == \"f\":\n",
    "        print('Exiting')\n",
    "        sys.exit()\n",
    "    if query == '':\n",
    "        continue\n",
    "    result = pdf_qa(\n",
    "        {\"question\": query, \"chat_history\": chat_history})\n",
    "    print(f\"{white}Answer: \" + result[\"answer\"])\n",
    "    chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
